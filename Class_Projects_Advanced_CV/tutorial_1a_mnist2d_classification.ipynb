{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/udlbook/udlbook/blob/main/Notebooks/Chap10/10_5_Convolution_For_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# **Tutorial 1a: MNIST-2D Classification**\n","\n","This tutorial builds a proper network for 2D convolution.  It works with the MNIST dataset, which was the original classic dataset for classifying images.  The network will take a 28x28 grayscale image and classify it into one of 10 classes representing a digit.\n","\n","The code is adapted from https://nextjournal.com/gkoehler/pytorch-mnist and https://github.com/udlbook/udlbook/blob/main/Notebooks/Chap10/10_5_Convolution_For_MNIST.ipynb\n","\n","Work through the cells below, running each cell in turn.\n"],"metadata":{"id":"t9vk9Elugvmi"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random"],"metadata":{"id":"YrXWAH7sUWvU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Loading in PyTorch\n","\n","In this section, we are setting up the data loaders for the MNIST dataset, which is a collection of handwritten digits commonly used for training various image processing systems. The MNIST dataset is available in PyTorch through the `torchvision` package.\n","\n","### Train DataLoader\n","- **Batch Size for Training:** `batch_size_train = 64`  \n","  This specifies that each batch of data that will be fed to the model during training contains 64 images.\n","\n","- **DataLoader for Training Data:**  \n","  `train_loader` is an instance of `torch.utils.data.DataLoader`. It is responsible for loading the training data in batches. Here's how it's configured:\n","  - **Dataset:** We use `torchvision.datasets.MNIST`, specifying the `/files/` directory for storage, setting `train=True`, and enabling `download=True` to download the data if it's not already present.\n","  - **Transformations:**\n","    - `torchvision.transforms.ToTensor()`: Converts the images into PyTorch tensors.\n","    - `torchvision.transforms.Normalize((0.1307,), (0.3081,))`: Normalizes the tensor with a mean of 0.1307 and a standard deviation of 0.3081. These values are standard for MNIST.\n","  - **Shuffling:** The data is shuffled (`shuffle=True`) to ensure that each batch is different, helping the model to generalize better.\n","\n","### Test DataLoader\n","- **Batch Size for Testing:** `batch_size_test = 1000`  \n","  For testing, we use a larger batch size of 1000 since gradients are not backpropagated and thus, less memory is required.\n","\n","- **DataLoader for Test Data:**  \n","  `test_loader` is similar to `train_loader` but with `train=False` in the MNIST dataset loader. It loads the test data in batches to evaluate the model. The same transformations are applied as in the training data loader.\n","\n","Both these data loaders will be used in the training and evaluation of a neural network model on the MNIST dataset.\n"],"metadata":{"id":"CotuU-k4V1wt"}},{"cell_type":"code","source":["# Run this once to load the train and test data straight into a dataloader class\n","# that will provide the batches\n","batch_size_train = 64\n","batch_size_test = 1000\n","train_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.MNIST('/files/', train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=batch_size_train, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.MNIST('/files/', train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=batch_size_test, shuffle=True)"],"metadata":{"id":"wScBGXXFVadm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706234869277,"user_tz":-480,"elapsed":1796,"user":{"displayName":"Chen Change Loy","userId":"05499521047689607651"}},"outputId":"b998cf8d-e9e5-4994-d8ce-938bdf0f527a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /files/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 420640751.57it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /files/MNIST/raw/train-images-idx3-ubyte.gz to /files/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /files/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 91908720.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /files/MNIST/raw/train-labels-idx1-ubyte.gz to /files/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 178033552.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /files/MNIST/raw/t10k-images-idx3-ubyte.gz to /files/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 17429578.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting /files/MNIST/raw/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Visualizing MNIST Dataset Samples\n","\n","In this section, we are visualizing some samples from the MNIST test dataset. This helps in understanding the type of data we are dealing with, which is crucial for designing and debugging neural network models.\n","\n","### Extracting Data Samples\n","- `examples = enumerate(test_loader)`: Here, we create an iterable from the `test_loader`. This allows us to go through the batches in the test dataset.\n","- `batch_idx, (example_data, example_targets) = next(examples)`: This line retrieves the first batch from the test dataset. `batch_idx` is the index of the batch, `example_data` contains the images, and `example_targets` contains the corresponding labels.\n","\n","### Plotting the Images\n","- `fig = plt.figure()`: We start by creating a new figure for plotting.\n","- The loop `for i in range(6):` iterates through the first six images in the batch.\n","  - `plt.subplot(2,3,i+1)`: Creates a subplot for each image. The images are arranged in a 2x3 grid, and `i+1` is the position index in this grid.\n","  - `plt.tight_layout()`: Adjusts the layout so that the plots are neatly arranged.\n","  - `plt.imshow(example_data[i][0], cmap='gray', interpolation='none')`: Displays the `i`-th image. The `[0]` accesses the first channel of the image (since MNIST images are grayscale). `cmap='gray'` sets the color map to grayscale, and `interpolation='none'` displays the image without interpolating pixel values.\n","  - `plt.title(\"Ground Truth: {}\".format(example_targets[i]))`: Sets the title of each subplot to show the actual label (ground truth) of the image.\n","  - `plt.xticks([])` and `plt.yticks([])`: These commands remove the x and y-axis ticks for a cleaner look.\n","\n","- `plt.show()`: Finally, this command displays the figure with the six MNIST images and their labels.\n","\n","This visualization is a great way to verify that the data loading process is working correctly and to get a sense of the MNIST dataset's contents.\n"],"metadata":{"id":"tRAfihLNWZ3R"}},{"cell_type":"code","source":["# Let's draw some of the training data\n","examples = enumerate(test_loader)\n","batch_idx, (example_data, example_targets) = next(examples)\n","\n","fig = plt.figure()\n","for i in range(6):\n","  plt.subplot(2,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n","  plt.xticks([])\n","  plt.yticks([])\n","plt.show()"],"metadata":{"id":"8bKADvLHbiV5","colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"status":"ok","timestamp":1706234876047,"user_tz":-480,"elapsed":2341,"user":{"displayName":"Chen Change Loy","userId":"05499521047689607651"}},"outputId":"c4e86079-eb4e-4822-9df9-399840630296"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 6 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Custom Neural Network Architecture in PyTorch\n","\n","The following code snippet is a template for a custom neural network class in PyTorch, with a set of instructions to implement specific layers and operations.\n","\n","### Implementation of `Net` Class\n","- The `Net` class is derived from `nn.Module`, which is a base class for all neural network modules in PyTorch.\n","- **Constructor (`__init__`):**\n","  - `self.conv1 = nn.Conv2d(1, 2, kernel_size=3)`: A convolutional layer with a kernel size of 3, 1 input channel, and 2 output channels.\n","  - `self.drop = nn.Dropout2d()`: A dropout layer that randomly zeroes some of the elements of the input tensor with a default probability of 0.5 during training, which helps prevent overfitting.\n","  - `self.fc1 = nn.Linear(338, 10)`: A fully connected (linear) layer that maps from 338 input features to 10 output features.\n","- **Forward Pass (`forward`):**\n","  - The forward pass defines how the input `x` flows through the network layers.\n","  - `x` goes through the convolutional layer, dropout, max pooling, ReLU activation, flattening, fully connected layer, and finally a log softmax function.\n"],"metadata":{"id":"q62kLYA1XaQQ"}},{"cell_type":"code","source":["from os import X_OK\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Valid convolution, 1 channel in, 2 channels out, stride 1, kernel size = 3\n","        self.conv1 = nn.Conv2d(1, 2, kernel_size=3)\n","        # Dropout for convolutions\n","        self.drop = nn.Dropout2d()\n","        # Fully connected layer\n","        self.fc1 = nn.Linear(338, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.drop(x)\n","        x = F.max_pool2d(x,2)\n","        x = F.relu(x)\n","        x = x.flatten(1)\n","        x = self.fc1(x)\n","        x = F.log_softmax(x)\n","        return x"],"metadata":{"id":"EQkvw2KOPVl7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## He Initialization in PyTorch\n","\n","In this section, we define a function `weights_init` to apply He initialization (also known as Kaiming initialization) to the weights of linear layers in a neural network. This initialization method is particularly effective for layers followed by ReLU activations.\n","\n","### Function: `weights_init`\n","- **Purpose:** This function is designed to initialize the weights of linear layers in a neural network using He initialization.\n","- **Parameter:** `layer_in`\n","  - The function takes a layer (`layer_in`) as its input.\n","- **He Initialization:**\n","  - `nn.init.kaiming_uniform_(layer_in.weight)`: If the layer is an instance of `nn.Linear`, its weights are initialized using the Kaiming uniform initialization. This method sets the weights uniformly in the range \\([-a, a]\\). See [TORCH.NN.INIT](https://pytorch.org/docs/stable/nn.init.html) for details.\n","  - `layer_in.bias.data.fill_(0.0)`: The bias terms of the layer are initialized to 0.\n","\n","### Why Use He Initialization?\n","- **Avoiding Vanishing/Exploding Gradients:** In deep networks, improper initialization can lead to the problem of vanishing or exploding gradients. This happens when the gradients are too small or too large, making the network difficult or impossible to train.\n","- **Relevance to ReLU:** He initialization is particularly effective when the network uses ReLU activation functions. It helps in maintaining a variance of 1 in the outputs of each layer, preventing the gradients from becoming too small during backpropagation.\n","- **Balanced Initial Weights:** By initializing the weights from a uniform distribution and considering the size of the previous layer, He initialization provides a good starting point for the learning process. This can lead to faster convergence during training and improved overall performance of the neural network.\n"],"metadata":{"id":"XfEdMsmTab82"}},{"cell_type":"code","source":["# He initialization of weights\n","def weights_init(layer_in):\n","  if isinstance(layer_in, nn.Linear):\n","    nn.init.kaiming_uniform_(layer_in.weight)\n","    layer_in.bias.data.fill_(0.0)"],"metadata":{"id":"qWZtkCZcU_dg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initializing and Setting Up the Neural Network\n","\n","In this code snippet, we are creating and initializing a neural network model, and then defining its optimizer. This setup is essential for preparing the model for the training process.\n","\n","### Network Creation\n","- `model = Net()`: This line creates an instance of the `Net` class, which defines our neural network.\n","\n","### Weight Initialization\n","- `model.apply(weights_init)`: Here, the `weights_init` function is applied to all the layers of the model. This function should be defined to initialize the weights of the network appropriately. In the context of neural networks, proper weight initialization can significantly impact the convergence and overall performance of the network during training.\n","\n","### Optimizer Definition\n","- `optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)`: This line defines the optimizer for the training process. Specifically, it:\n","  - Uses the Stochastic Gradient Descent (SGD) algorithm from PyTorch's `optim` package.\n","  - `model.parameters()`: Passes all the parameters of the model (weights and biases) to the optimizer.\n","  - `lr=0.01`: Sets the learning rate to 0.01. The learning rate controls how much to change the model in response to the estimated error each time the model weights are updated.\n","  - `momentum=0.5`: Sets the momentum to 0.5. Momentum helps accelerate the optimizer in the relevant direction and dampens oscillations."],"metadata":{"id":"77hFJYFQdYBB"}},{"cell_type":"code","source":["# Create network\n","model = Net()\n","# Initialize model weights\n","model.apply(weights_init)\n","# Define optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"],"metadata":{"id":"FslroPJJffrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEr3yensi68t","executionInfo":{"status":"ok","timestamp":1706235274619,"user_tz":-480,"elapsed":484,"user":{"displayName":"Chen Change Loy","userId":"05499521047689607651"}},"outputId":"b344ebc0-ef35-47df-deeb-8e5ac7afaa54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1))\n","  (drop): Dropout2d(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=338, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"markdown","source":["## Training Routine for the Neural Network\n","\n","This section of code outlines the main training routine for our neural network model.\n","\n","### Function: `train`\n","- **Purpose:** The `train` function is designed to train the model for one epoch. An epoch is one complete pass through the training dataset.\n","- **Parameter:** `epoch`  \n","  This parameter represents the current epoch number.\n","\n","### Training Process\n","- `model.train()`: This line sets the model to training mode. This is important because certain layers like dropout layers behave differently during training than during testing.\n","- **Iterating Over Batches:**\n","  - `for batch_idx, (data, target) in enumerate(train_loader)`: This loop iterates over the training data using the `train_loader`. `batch_idx` is the index of the current batch, `data` contains the input data, and `target` contains the corresponding labels.\n","- **Optimization Steps:**\n","  - `optimizer.zero_grad()`: Before the model performs backpropagation, we need to clear the existing gradients; otherwise, they will accumulate.\n","  - `output = model(data)`: The model computes its predictions based on the current batch of data.\n","  - `loss = F.nll_loss(output, target)`: The loss is calculated using the negative log likelihood loss function, which is common for classification tasks.\n","  - `loss.backward()`: This line computes the gradient of the loss with respect to all trainable parameters in the model.\n","  - `optimizer.step()`: The optimizer updates the weights based on the computed gradients.\n","- **Logging:**\n","  - The `if` condition `if batch_idx % 10 == 0:` checks if the current batch index is a multiple of 10. If so, it prints out the current training status, including the epoch, the number of data processed so far, the total size of the dataset, and the current loss."],"metadata":{"id":"jui7jvXdd74N"}},{"cell_type":"code","source":["# Main training routine\n","def train(epoch):\n","  model.train()\n","  # Get each\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    output = model(data)\n","    loss = F.nll_loss(output, target)\n","    loss.backward()\n","    optimizer.step()\n","    # Store results\n","    if batch_idx % 10 == 0:\n","      print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n","        epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()))"],"metadata":{"id":"xKQd9PzkQ766"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the Neural Network on Test Data\n","\n","This section of the code defines the `test` function, which is used to evaluate the performance of the neural network model on the test dataset.\n","\n","### Function: `test`\n","- **Purpose:** The function assesses the model's performance on the test dataset by calculating the average loss and the accuracy.\n","\n","### Testing Process\n","- `model.eval()`: This line sets the model to evaluation mode. It is important as certain layers like dropout layers behave differently during evaluation than during training.\n","- **Initialization:**\n","  - `test_loss = 0`: A variable to accumulate the loss over the test dataset.\n","  - `correct = 0`: A counter for the number of correct predictions.\n","- **No Gradient Calculations:**\n","  - `with torch.no_grad()`: This context manager disables gradient calculation, which reduces memory consumption and speeds up computations, since gradients are not needed for evaluation.\n","- **Iterating Over the Test Data:**\n","  - `for data, target in test_loader`: This loop iterates over the test data using `test_loader`. `data` contains the input data, and `target` contains the corresponding labels.\n","  - `output = model(data)`: The model makes predictions based on the current batch of data.\n","  - `test_loss += F.nll_loss(output, target, size_average=False).item()`: The loss is calculated using the negative log likelihood loss function and accumulated.\n","  - `pred = output.data.max(1, keepdim=True)[1]`: The predictions are obtained by finding the index of the maximum log-probability.\n","  - `correct += pred.eq(target.data.view_as(pred)).sum()`: Counts the number of correct predictions by comparing `pred` with the actual `target`.\n","- **Final Loss and Accuracy Calculation:**\n","  - `test_loss /= len(test_loader.dataset)`: The total loss is averaged over the number of examples in the test dataset.\n","  - The final print statement reports the average test loss and the accuracy of the model.\n","\n"],"metadata":{"id":"W69Psb-aef_i"}},{"cell_type":"code","source":["# Run on test data\n","def test():\n","  model.eval()\n","  test_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data, target in test_loader:\n","      output = model(data)\n","      test_loss += F.nll_loss(output, target, size_average=False).item()\n","      pred = output.data.max(1, keepdim=True)[1]\n","      correct += pred.eq(target.data.view_as(pred)).sum()\n","  test_loss /= len(test_loader.dataset)\n","  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(test_loader.dataset),\n","    100. * correct / len(test_loader.dataset)))"],"metadata":{"id":"Byn-f7qWRLxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get initial performance\n","test()\n","# Train for three epochs\n","n_epochs = 3\n","for epoch in range(1, n_epochs + 1):\n","  train(epoch)\n","  test()"],"metadata":{"id":"YgLaex1pfhqz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706234967317,"user_tz":-480,"elapsed":62292,"user":{"displayName":"Chen Change Loy","userId":"05499521047689607651"}},"outputId":"db14b59c-cf89-43d2-87e0-ea1f5451f317"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-e89a9d90efd6>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.log_softmax(x)\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Avg. loss: 2.4132, Accuracy: 892/10000 (9%)\n","\n","Train Epoch: 1 [0/60000]\tLoss: 2.390304\n","Train Epoch: 1 [640/60000]\tLoss: 2.365330\n","Train Epoch: 1 [1280/60000]\tLoss: 2.317568\n","Train Epoch: 1 [1920/60000]\tLoss: 2.295605\n","Train Epoch: 1 [2560/60000]\tLoss: 2.280946\n","Train Epoch: 1 [3200/60000]\tLoss: 2.261410\n","Train Epoch: 1 [3840/60000]\tLoss: 2.248566\n","Train Epoch: 1 [4480/60000]\tLoss: 2.245144\n","Train Epoch: 1 [5120/60000]\tLoss: 2.076128\n","Train Epoch: 1 [5760/60000]\tLoss: 2.060066\n","Train Epoch: 1 [6400/60000]\tLoss: 1.954514\n","Train Epoch: 1 [7040/60000]\tLoss: 1.945989\n","Train Epoch: 1 [7680/60000]\tLoss: 1.823616\n","Train Epoch: 1 [8320/60000]\tLoss: 1.811078\n","Train Epoch: 1 [8960/60000]\tLoss: 1.708416\n","Train Epoch: 1 [9600/60000]\tLoss: 1.712904\n","Train Epoch: 1 [10240/60000]\tLoss: 1.293424\n","Train Epoch: 1 [10880/60000]\tLoss: 1.644754\n","Train Epoch: 1 [11520/60000]\tLoss: 1.601322\n","Train Epoch: 1 [12160/60000]\tLoss: 1.260821\n","Train Epoch: 1 [12800/60000]\tLoss: 1.024196\n","Train Epoch: 1 [13440/60000]\tLoss: 1.248831\n","Train Epoch: 1 [14080/60000]\tLoss: 1.114688\n","Train Epoch: 1 [14720/60000]\tLoss: 1.279264\n","Train Epoch: 1 [15360/60000]\tLoss: 1.165446\n","Train Epoch: 1 [16000/60000]\tLoss: 1.141992\n","Train Epoch: 1 [16640/60000]\tLoss: 1.218082\n","Train Epoch: 1 [17280/60000]\tLoss: 1.055405\n","Train Epoch: 1 [17920/60000]\tLoss: 1.174596\n","Train Epoch: 1 [18560/60000]\tLoss: 1.116982\n","Train Epoch: 1 [19200/60000]\tLoss: 1.181232\n","Train Epoch: 1 [19840/60000]\tLoss: 1.051612\n","Train Epoch: 1 [20480/60000]\tLoss: 1.142519\n","Train Epoch: 1 [21120/60000]\tLoss: 0.993324\n","Train Epoch: 1 [21760/60000]\tLoss: 1.123582\n","Train Epoch: 1 [22400/60000]\tLoss: 1.262531\n","Train Epoch: 1 [23040/60000]\tLoss: 1.064739\n","Train Epoch: 1 [23680/60000]\tLoss: 1.101078\n","Train Epoch: 1 [24320/60000]\tLoss: 1.098658\n","Train Epoch: 1 [24960/60000]\tLoss: 1.405049\n","Train Epoch: 1 [25600/60000]\tLoss: 1.111934\n","Train Epoch: 1 [26240/60000]\tLoss: 1.076785\n","Train Epoch: 1 [26880/60000]\tLoss: 0.898336\n","Train Epoch: 1 [27520/60000]\tLoss: 1.131222\n","Train Epoch: 1 [28160/60000]\tLoss: 1.114051\n","Train Epoch: 1 [28800/60000]\tLoss: 0.714854\n","Train Epoch: 1 [29440/60000]\tLoss: 1.077639\n","Train Epoch: 1 [30080/60000]\tLoss: 0.840387\n","Train Epoch: 1 [30720/60000]\tLoss: 0.836582\n","Train Epoch: 1 [31360/60000]\tLoss: 0.738043\n","Train Epoch: 1 [32000/60000]\tLoss: 1.405944\n","Train Epoch: 1 [32640/60000]\tLoss: 1.072750\n","Train Epoch: 1 [33280/60000]\tLoss: 0.834015\n","Train Epoch: 1 [33920/60000]\tLoss: 1.059928\n","Train Epoch: 1 [34560/60000]\tLoss: 0.979056\n","Train Epoch: 1 [35200/60000]\tLoss: 0.959052\n","Train Epoch: 1 [35840/60000]\tLoss: 0.880027\n","Train Epoch: 1 [36480/60000]\tLoss: 1.065104\n","Train Epoch: 1 [37120/60000]\tLoss: 1.020619\n","Train Epoch: 1 [37760/60000]\tLoss: 1.053911\n","Train Epoch: 1 [38400/60000]\tLoss: 1.047349\n","Train Epoch: 1 [39040/60000]\tLoss: 0.992627\n","Train Epoch: 1 [39680/60000]\tLoss: 0.996558\n","Train Epoch: 1 [40320/60000]\tLoss: 1.065121\n","Train Epoch: 1 [40960/60000]\tLoss: 0.831403\n","Train Epoch: 1 [41600/60000]\tLoss: 0.784950\n","Train Epoch: 1 [42240/60000]\tLoss: 1.008842\n","Train Epoch: 1 [42880/60000]\tLoss: 0.755078\n","Train Epoch: 1 [43520/60000]\tLoss: 1.366370\n","Train Epoch: 1 [44160/60000]\tLoss: 0.927024\n","Train Epoch: 1 [44800/60000]\tLoss: 1.124123\n","Train Epoch: 1 [45440/60000]\tLoss: 0.817982\n","Train Epoch: 1 [46080/60000]\tLoss: 0.911356\n","Train Epoch: 1 [46720/60000]\tLoss: 1.099744\n","Train Epoch: 1 [47360/60000]\tLoss: 0.883401\n","Train Epoch: 1 [48000/60000]\tLoss: 0.834528\n","Train Epoch: 1 [48640/60000]\tLoss: 1.100217\n","Train Epoch: 1 [49280/60000]\tLoss: 1.003456\n","Train Epoch: 1 [49920/60000]\tLoss: 0.899432\n","Train Epoch: 1 [50560/60000]\tLoss: 0.969666\n","Train Epoch: 1 [51200/60000]\tLoss: 1.162928\n","Train Epoch: 1 [51840/60000]\tLoss: 1.178254\n","Train Epoch: 1 [52480/60000]\tLoss: 0.878752\n","Train Epoch: 1 [53120/60000]\tLoss: 0.965254\n","Train Epoch: 1 [53760/60000]\tLoss: 1.020232\n","Train Epoch: 1 [54400/60000]\tLoss: 1.000340\n","Train Epoch: 1 [55040/60000]\tLoss: 0.982072\n","Train Epoch: 1 [55680/60000]\tLoss: 0.895505\n","Train Epoch: 1 [56320/60000]\tLoss: 0.798514\n","Train Epoch: 1 [56960/60000]\tLoss: 1.338432\n","Train Epoch: 1 [57600/60000]\tLoss: 0.776266\n","Train Epoch: 1 [58240/60000]\tLoss: 0.860986\n","Train Epoch: 1 [58880/60000]\tLoss: 0.806423\n","Train Epoch: 1 [59520/60000]\tLoss: 0.759907\n","\n","Test set: Avg. loss: 0.3643, Accuracy: 8997/10000 (90%)\n","\n","Train Epoch: 2 [0/60000]\tLoss: 0.758940\n","Train Epoch: 2 [640/60000]\tLoss: 1.032504\n","Train Epoch: 2 [1280/60000]\tLoss: 1.027992\n","Train Epoch: 2 [1920/60000]\tLoss: 0.971811\n","Train Epoch: 2 [2560/60000]\tLoss: 1.006463\n","Train Epoch: 2 [3200/60000]\tLoss: 1.043793\n","Train Epoch: 2 [3840/60000]\tLoss: 1.355815\n","Train Epoch: 2 [4480/60000]\tLoss: 0.803670\n","Train Epoch: 2 [5120/60000]\tLoss: 0.942280\n","Train Epoch: 2 [5760/60000]\tLoss: 1.031842\n","Train Epoch: 2 [6400/60000]\tLoss: 0.795064\n","Train Epoch: 2 [7040/60000]\tLoss: 0.842066\n","Train Epoch: 2 [7680/60000]\tLoss: 1.024837\n","Train Epoch: 2 [8320/60000]\tLoss: 1.090405\n","Train Epoch: 2 [8960/60000]\tLoss: 1.229002\n","Train Epoch: 2 [9600/60000]\tLoss: 1.017049\n","Train Epoch: 2 [10240/60000]\tLoss: 0.822253\n","Train Epoch: 2 [10880/60000]\tLoss: 1.420186\n","Train Epoch: 2 [11520/60000]\tLoss: 1.029621\n","Train Epoch: 2 [12160/60000]\tLoss: 0.996644\n","Train Epoch: 2 [12800/60000]\tLoss: 0.708289\n","Train Epoch: 2 [13440/60000]\tLoss: 0.689082\n","Train Epoch: 2 [14080/60000]\tLoss: 0.885301\n","Train Epoch: 2 [14720/60000]\tLoss: 1.050305\n","Train Epoch: 2 [15360/60000]\tLoss: 1.038768\n","Train Epoch: 2 [16000/60000]\tLoss: 1.038048\n","Train Epoch: 2 [16640/60000]\tLoss: 0.884545\n","Train Epoch: 2 [17280/60000]\tLoss: 0.939059\n","Train Epoch: 2 [17920/60000]\tLoss: 0.896646\n","Train Epoch: 2 [18560/60000]\tLoss: 0.705778\n","Train Epoch: 2 [19200/60000]\tLoss: 0.929242\n","Train Epoch: 2 [19840/60000]\tLoss: 0.673447\n","Train Epoch: 2 [20480/60000]\tLoss: 0.873920\n","Train Epoch: 2 [21120/60000]\tLoss: 0.855814\n","Train Epoch: 2 [21760/60000]\tLoss: 1.059478\n","Train Epoch: 2 [22400/60000]\tLoss: 1.053484\n","Train Epoch: 2 [23040/60000]\tLoss: 1.086602\n","Train Epoch: 2 [23680/60000]\tLoss: 0.884809\n","Train Epoch: 2 [24320/60000]\tLoss: 1.062107\n","Train Epoch: 2 [24960/60000]\tLoss: 0.710366\n","Train Epoch: 2 [25600/60000]\tLoss: 0.933173\n","Train Epoch: 2 [26240/60000]\tLoss: 0.711134\n","Train Epoch: 2 [26880/60000]\tLoss: 0.725393\n","Train Epoch: 2 [27520/60000]\tLoss: 0.598313\n","Train Epoch: 2 [28160/60000]\tLoss: 0.747945\n","Train Epoch: 2 [28800/60000]\tLoss: 0.764313\n","Train Epoch: 2 [29440/60000]\tLoss: 0.906221\n","Train Epoch: 2 [30080/60000]\tLoss: 1.095484\n","Train Epoch: 2 [30720/60000]\tLoss: 0.981475\n","Train Epoch: 2 [31360/60000]\tLoss: 1.053261\n","Train Epoch: 2 [32000/60000]\tLoss: 0.732864\n","Train Epoch: 2 [32640/60000]\tLoss: 0.770232\n","Train Epoch: 2 [33280/60000]\tLoss: 1.161232\n","Train Epoch: 2 [33920/60000]\tLoss: 0.907376\n","Train Epoch: 2 [34560/60000]\tLoss: 1.152072\n","Train Epoch: 2 [35200/60000]\tLoss: 0.898806\n","Train Epoch: 2 [35840/60000]\tLoss: 0.752273\n","Train Epoch: 2 [36480/60000]\tLoss: 0.819518\n","Train Epoch: 2 [37120/60000]\tLoss: 1.084478\n","Train Epoch: 2 [37760/60000]\tLoss: 0.742445\n","Train Epoch: 2 [38400/60000]\tLoss: 0.760159\n","Train Epoch: 2 [39040/60000]\tLoss: 1.067544\n","Train Epoch: 2 [39680/60000]\tLoss: 0.701544\n","Train Epoch: 2 [40320/60000]\tLoss: 0.736864\n","Train Epoch: 2 [40960/60000]\tLoss: 0.912039\n","Train Epoch: 2 [41600/60000]\tLoss: 0.887918\n","Train Epoch: 2 [42240/60000]\tLoss: 0.645970\n","Train Epoch: 2 [42880/60000]\tLoss: 1.076914\n","Train Epoch: 2 [43520/60000]\tLoss: 0.935553\n","Train Epoch: 2 [44160/60000]\tLoss: 0.914847\n","Train Epoch: 2 [44800/60000]\tLoss: 0.697664\n","Train Epoch: 2 [45440/60000]\tLoss: 1.101386\n","Train Epoch: 2 [46080/60000]\tLoss: 0.874037\n","Train Epoch: 2 [46720/60000]\tLoss: 0.647669\n","Train Epoch: 2 [47360/60000]\tLoss: 0.851916\n","Train Epoch: 2 [48000/60000]\tLoss: 1.160736\n","Train Epoch: 2 [48640/60000]\tLoss: 0.698802\n","Train Epoch: 2 [49280/60000]\tLoss: 0.789289\n","Train Epoch: 2 [49920/60000]\tLoss: 1.017052\n","Train Epoch: 2 [50560/60000]\tLoss: 0.833229\n","Train Epoch: 2 [51200/60000]\tLoss: 0.738227\n","Train Epoch: 2 [51840/60000]\tLoss: 0.592602\n","Train Epoch: 2 [52480/60000]\tLoss: 0.832885\n","Train Epoch: 2 [53120/60000]\tLoss: 1.024823\n","Train Epoch: 2 [53760/60000]\tLoss: 0.971382\n","Train Epoch: 2 [54400/60000]\tLoss: 0.791991\n","Train Epoch: 2 [55040/60000]\tLoss: 1.099427\n","Train Epoch: 2 [55680/60000]\tLoss: 0.766222\n","Train Epoch: 2 [56320/60000]\tLoss: 0.936432\n","Train Epoch: 2 [56960/60000]\tLoss: 0.645070\n","Train Epoch: 2 [57600/60000]\tLoss: 0.712056\n","Train Epoch: 2 [58240/60000]\tLoss: 0.908456\n","Train Epoch: 2 [58880/60000]\tLoss: 1.132795\n","Train Epoch: 2 [59520/60000]\tLoss: 0.965531\n","\n","Test set: Avg. loss: 0.3533, Accuracy: 9010/10000 (90%)\n","\n","Train Epoch: 3 [0/60000]\tLoss: 1.137162\n","Train Epoch: 3 [640/60000]\tLoss: 0.901673\n","Train Epoch: 3 [1280/60000]\tLoss: 1.002282\n","Train Epoch: 3 [1920/60000]\tLoss: 1.011381\n","Train Epoch: 3 [2560/60000]\tLoss: 0.929340\n","Train Epoch: 3 [3200/60000]\tLoss: 1.041348\n","Train Epoch: 3 [3840/60000]\tLoss: 0.646075\n","Train Epoch: 3 [4480/60000]\tLoss: 1.069411\n","Train Epoch: 3 [5120/60000]\tLoss: 1.130617\n","Train Epoch: 3 [5760/60000]\tLoss: 0.794500\n","Train Epoch: 3 [6400/60000]\tLoss: 0.763339\n","Train Epoch: 3 [7040/60000]\tLoss: 0.964163\n","Train Epoch: 3 [7680/60000]\tLoss: 0.906923\n","Train Epoch: 3 [8320/60000]\tLoss: 0.961740\n","Train Epoch: 3 [8960/60000]\tLoss: 1.104166\n","Train Epoch: 3 [9600/60000]\tLoss: 0.927754\n","Train Epoch: 3 [10240/60000]\tLoss: 0.950795\n","Train Epoch: 3 [10880/60000]\tLoss: 0.697146\n","Train Epoch: 3 [11520/60000]\tLoss: 0.733259\n","Train Epoch: 3 [12160/60000]\tLoss: 0.999663\n","Train Epoch: 3 [12800/60000]\tLoss: 0.891964\n","Train Epoch: 3 [13440/60000]\tLoss: 0.617194\n","Train Epoch: 3 [14080/60000]\tLoss: 1.087998\n","Train Epoch: 3 [14720/60000]\tLoss: 1.185307\n","Train Epoch: 3 [15360/60000]\tLoss: 1.015619\n","Train Epoch: 3 [16000/60000]\tLoss: 0.957135\n","Train Epoch: 3 [16640/60000]\tLoss: 0.597632\n","Train Epoch: 3 [17280/60000]\tLoss: 0.986003\n","Train Epoch: 3 [17920/60000]\tLoss: 1.067698\n","Train Epoch: 3 [18560/60000]\tLoss: 1.573364\n","Train Epoch: 3 [19200/60000]\tLoss: 0.863232\n","Train Epoch: 3 [19840/60000]\tLoss: 0.941938\n","Train Epoch: 3 [20480/60000]\tLoss: 0.980663\n","Train Epoch: 3 [21120/60000]\tLoss: 0.847646\n","Train Epoch: 3 [21760/60000]\tLoss: 1.171988\n","Train Epoch: 3 [22400/60000]\tLoss: 0.909467\n","Train Epoch: 3 [23040/60000]\tLoss: 1.071135\n","Train Epoch: 3 [23680/60000]\tLoss: 0.733761\n","Train Epoch: 3 [24320/60000]\tLoss: 0.973796\n","Train Epoch: 3 [24960/60000]\tLoss: 0.803068\n","Train Epoch: 3 [25600/60000]\tLoss: 0.857522\n","Train Epoch: 3 [26240/60000]\tLoss: 1.051601\n","Train Epoch: 3 [26880/60000]\tLoss: 1.001450\n","Train Epoch: 3 [27520/60000]\tLoss: 1.185196\n","Train Epoch: 3 [28160/60000]\tLoss: 0.796780\n","Train Epoch: 3 [28800/60000]\tLoss: 0.855536\n","Train Epoch: 3 [29440/60000]\tLoss: 0.650253\n","Train Epoch: 3 [30080/60000]\tLoss: 1.097842\n","Train Epoch: 3 [30720/60000]\tLoss: 0.847087\n","Train Epoch: 3 [31360/60000]\tLoss: 0.893068\n","Train Epoch: 3 [32000/60000]\tLoss: 0.718695\n","Train Epoch: 3 [32640/60000]\tLoss: 0.564492\n","Train Epoch: 3 [33280/60000]\tLoss: 0.930472\n","Train Epoch: 3 [33920/60000]\tLoss: 0.906437\n","Train Epoch: 3 [34560/60000]\tLoss: 0.538993\n","Train Epoch: 3 [35200/60000]\tLoss: 0.734518\n","Train Epoch: 3 [35840/60000]\tLoss: 0.934541\n","Train Epoch: 3 [36480/60000]\tLoss: 0.850748\n","Train Epoch: 3 [37120/60000]\tLoss: 0.697037\n","Train Epoch: 3 [37760/60000]\tLoss: 0.799635\n","Train Epoch: 3 [38400/60000]\tLoss: 0.977171\n","Train Epoch: 3 [39040/60000]\tLoss: 1.090442\n","Train Epoch: 3 [39680/60000]\tLoss: 0.838321\n","Train Epoch: 3 [40320/60000]\tLoss: 0.743593\n","Train Epoch: 3 [40960/60000]\tLoss: 0.789672\n","Train Epoch: 3 [41600/60000]\tLoss: 0.775878\n","Train Epoch: 3 [42240/60000]\tLoss: 0.968211\n","Train Epoch: 3 [42880/60000]\tLoss: 0.966440\n","Train Epoch: 3 [43520/60000]\tLoss: 0.776899\n","Train Epoch: 3 [44160/60000]\tLoss: 0.895175\n","Train Epoch: 3 [44800/60000]\tLoss: 0.776350\n","Train Epoch: 3 [45440/60000]\tLoss: 0.878604\n","Train Epoch: 3 [46080/60000]\tLoss: 0.965116\n","Train Epoch: 3 [46720/60000]\tLoss: 0.995083\n","Train Epoch: 3 [47360/60000]\tLoss: 0.895525\n","Train Epoch: 3 [48000/60000]\tLoss: 0.899714\n","Train Epoch: 3 [48640/60000]\tLoss: 1.277156\n","Train Epoch: 3 [49280/60000]\tLoss: 0.978665\n","Train Epoch: 3 [49920/60000]\tLoss: 0.905190\n","Train Epoch: 3 [50560/60000]\tLoss: 1.102894\n","Train Epoch: 3 [51200/60000]\tLoss: 0.988996\n","Train Epoch: 3 [51840/60000]\tLoss: 0.665187\n","Train Epoch: 3 [52480/60000]\tLoss: 1.116115\n","Train Epoch: 3 [53120/60000]\tLoss: 1.098164\n","Train Epoch: 3 [53760/60000]\tLoss: 0.795897\n","Train Epoch: 3 [54400/60000]\tLoss: 0.934605\n","Train Epoch: 3 [55040/60000]\tLoss: 0.759587\n","Train Epoch: 3 [55680/60000]\tLoss: 0.668330\n","Train Epoch: 3 [56320/60000]\tLoss: 0.842855\n","Train Epoch: 3 [56960/60000]\tLoss: 0.817111\n","Train Epoch: 3 [57600/60000]\tLoss: 0.568985\n","Train Epoch: 3 [58240/60000]\tLoss: 1.007633\n","Train Epoch: 3 [58880/60000]\tLoss: 1.124054\n","Train Epoch: 3 [59520/60000]\tLoss: 0.812142\n","\n","Test set: Avg. loss: 0.3343, Accuracy: 9060/10000 (91%)\n","\n"]}]},{"cell_type":"markdown","source":["## Visualizing Convolutional Filters in a Neural Network\n","\n","The `visualize_filters` function is designed to extract and display the filters from the first convolutional layer of a provided neural network model. This visualization can be quite helpful in understanding what features your convolutional neural network is learning.\n","\n","### Function: `visualize_filters`\n","- **Purpose:** To visually inspect the filters in the first convolutional layer of the neural network.\n","- **Parameter:** `model`  \n","  The neural network model whose filters are to be visualized.\n","\n","### Visualization Process\n","- **Extract Filters:**\n","  - `conv1_weights = model.conv1.weight.data.numpy()`: This line extracts the weights of the first convolutional layer (`conv1`) of the model and converts them into a NumPy array. These weights represent the filters.\n","- **Determine Number of Filters:**\n","  - `num_filters = conv1_weights.shape[0]`: Determines the number of filters in the convolutional layer by checking the first dimension of the `conv1_weights` array.\n","- **Plotting:**\n","  - `fig = plt.figure(figsize=(10, 5))`: Creates a new figure for plotting with a specified size.\n","  - The loop `for i in range(num_filters):` iterates through each filter.\n","    - `ax = fig.add_subplot(1, num_filters, i+1)`: Creates a subplot for each filter in a 1-row grid.\n","    - `ax.imshow(conv1_weights[i, 0, :, :], cmap='gray')`: Displays the `i`-th filter. The filters are shown in grayscale for easier interpretation.\n","    - `ax.set_title('Filter {}'.format(i+1))`: Sets a title for each subplot indicating the filter number.\n","    - `plt.xticks([])` and `plt.yticks([])`: These commands remove the x and y-axis ticks for a cleaner look of each filter.\n","  - `plt.show()`: Displays the figure with all the filters.\n","\n","### Execution\n","- `visualize_filters(model)`: This line calls the `visualize_filters` function with the neural network model `model` as an argument, which will execute the visualization of the filters in the model's first convolutional layer.\n"],"metadata":{"id":"SvAps6TUjJ40"}},{"cell_type":"code","source":["def visualize_filters(model):\n","    # Extract the weights from the first convolutional layer\n","    conv1_weights = model.conv1.weight.data.numpy()\n","\n","    # Number of filters\n","    num_filters = conv1_weights.shape[0]\n","\n","    fig = plt.figure(figsize=(10, 5))\n","    for i in range(num_filters):\n","        ax = fig.add_subplot(1, num_filters, i+1)\n","        # Display each filter\n","        ax.imshow(conv1_weights[i, 0, :, :], cmap='gray')\n","        ax.set_title('Filter {}'.format(i+1))\n","        plt.xticks([])\n","        plt.yticks([])\n","\n","    plt.show()\n","\n","visualize_filters(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"gFPf_KH9iXwQ","executionInfo":{"status":"ok","timestamp":1706235137464,"user_tz":-480,"elapsed":480,"user":{"displayName":"Chen Change Loy","userId":"05499521047689607651"}},"outputId":"4f6aae64-ec58-456b-c17f-b034729713d3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Run network on data we got before and show predictions\n","output = model(example_data)\n","\n","fig = plt.figure()\n","for i in range(10):\n","  plt.subplot(5,5,i+1)\n","  plt.tight_layout()\n","  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","  plt.title(\"Prediction: {}\".format(\n","    output.data.max(1, keepdim=True)[1][i].item()))\n","  plt.xticks([])\n","  plt.yticks([])\n","plt.show()"],"metadata":{"id":"o7fRUAy9Se1B","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1705918264304,"user_tz":-480,"elapsed":1093,"user":{"displayName":"Chen Change Loy","userId":"05499521047689607651"}},"outputId":"941c7b6f-8533-471c-ddf8-08ba4be44465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-4e4b7d3d78d6>:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.log_softmax(x)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## What's Next?\n","\n","We have sketched a simple framework for training CNNs. There are a few more functions yet to be completed.\n","\n","  - Adjust the learning rate and batch size and observe the training curve\n","  - Plot a chart for the accuracy\n","  - Average the loss during each epoch when plotting a chart\n","  - Consider data augmentations\n","\n","Please check the official [Tutorials](https://pytorch.org/tutorials) and [Examples](https://github.com/pytorch/examples) on for more details."],"metadata":{"id":"XnmIP8_bfUgv"}}]}